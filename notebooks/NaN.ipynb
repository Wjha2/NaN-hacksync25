{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N44hzUs1ZQQ8",
        "outputId": "fa974953-c543-43d7-bcfc-978d2e897213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-4025a155d312>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
            "<ipython-input-1-4025a155d312>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)  # Fill categorical with mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete. Scaler saved as 'scaler.pkl'.\n",
            "Preprocessing complete. Processed dataset saved as 'processed_wellbeing_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "# Load the dataset\n",
        "file_path = \"Wellbeing_and_lifestyle_data_Kaggle.csv\"  # Adjust the path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=['Timestamp'], inplace=True)\n",
        "\n",
        "# Handle missing values\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)  # Fill categorical with mode\n",
        "    else:\n",
        "        df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
        "\n",
        "# Convert categorical features to numerical using Label Encoding\n",
        "label_encoders = {}\n",
        "categorical_features = ['DAILY_STRESS', 'AGE', 'GENDER']\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Identify and remove outliers using the IQR method\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "# Identify numerical features\n",
        "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "# Save the scaler for later use\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "print(\"Preprocessing complete. Scaler saved as 'scaler.pkl'.\")\n",
        "# Save preprocessed dataset\n",
        "df.to_csv(\"processed_wellbeing_data.csv\", index=False)\n",
        "\n",
        "# Display completion message\n",
        "print(\"Preprocessing complete. Processed dataset saved as 'processed_wellbeing_data.csv'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ composite scores <br>\n",
        "SOCIAL_ACTIVITY_SCORE (based on social interactions).<br>\n",
        "WORK_PRODUCTIVITY_SCORE (task completion & achievements).<br>\n",
        "SELF_CARE_SCORE (sleep, meditation, personal time).<br>\n",
        "STRESS_IMPACT (daily stress impact).<br>\n",
        "✅binary target variables:<br>\n",
        "\n",
        "COGNITIVE_OVERLOAD: 1 if stress levels are high.<br>\n",
        "SOCIAL_ENGAGEMENT_NEEDS: 1 if social interaction is low.<br>\n",
        "WORK_LIFE_BALANCE_ADJUST: 1 if work-life balance is poor."
      ],
      "metadata": {
        "id": "jxkMGsv0aKvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering: Creating meaningful features\n",
        "df['SOCIAL_ACTIVITY_SCORE'] = df['PLACES_VISITED'] + df['SOCIAL_NETWORK'] + df['SUPPORTING_OTHERS']\n",
        "df['WORK_PRODUCTIVITY_SCORE'] = df['ACHIEVEMENT'] + df['TODO_COMPLETED'] + df['PERSONAL_AWARDS']\n",
        "df['SELF_CARE_SCORE'] = df['SLEEP_HOURS'] + df['TIME_FOR_PASSION'] + df['WEEKLY_MEDITATION']\n",
        "df['STRESS_IMPACT'] = df['DAILY_STRESS'] + df['DAILY_SHOUTING'] - df['LIVE_VISION']\n",
        "\n",
        "# Binary Labels for Cognitive Overload (1: Overloaded, 0: Not Overloaded)\n",
        "df['COGNITIVE_OVERLOAD'] = np.where(df['DAILY_STRESS'] > df['DAILY_STRESS'].median(), 1, 0)\n",
        "\n",
        "# Social Engagement Needs (1: Needs more engagement, 0: Well engaged)\n",
        "df['SOCIAL_ENGAGEMENT_NEEDS'] = np.where(df['SOCIAL_NETWORK'] < df['SOCIAL_NETWORK'].median(), 1, 0)\n",
        "\n",
        "# Work-Life Balance Classification (1: Needs Adjustment, 0: Balanced)\n",
        "df['WORK_LIFE_BALANCE_ADJUST'] = np.where(df['WORK_LIFE_BALANCE_SCORE'] < df['WORK_LIFE_BALANCE_SCORE'].median(), 1, 0)\n",
        "\n",
        "# Save the new dataset with engineered features\n",
        "df.to_csv(\"engineered_wellbeing_data.csv\", index=False)\n",
        "\n",
        "print(\"Feature engineering complete. Dataset saved as 'engineered_wellbeing_data.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMVeKlTGZiKA",
        "outputId": "9f741cb2-6f24-4c91-fc89-868807783365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering complete. Dataset saved as 'engineered_wellbeing_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model for Cognitive Overload Prediction<bR>\n",
        "We'll use:<br>\n",
        " ✅ Logistic Regression as a baseline model.<br>\n",
        "✅ Random Forest Classifier for improved accuracy.<br>\n",
        "✅ XGBoost Classifier for optimized performance."
      ],
      "metadata": {
        "id": "Lgz11dEPaD4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset with engineered features\n",
        "df = pd.read_csv(\"engineered_wellbeing_data.csv\")\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['SOCIAL_ACTIVITY_SCORE', 'WORK_PRODUCTIVITY_SCORE', 'SELF_CARE_SCORE', 'STRESS_IMPACT']\n",
        "X = df[features]\n",
        "y = df['COGNITIVE_OVERLOAD']  # Target variable (1: Overloaded, 0: Not Overloaded)\n",
        "\n",
        "# Split the data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression Model (Baseline)\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train, y_train)\n",
        "log_preds = log_model.predict(X_test)\n",
        "log_acc = accuracy_score(y_test, log_preds)\n",
        "print(\"Logistic Regression Accuracy:\", log_acc)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, rf_preds)\n",
        "print(\"Random Forest Accuracy:\", rf_acc)\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "print(\"XGBoost Accuracy:\", xgb_acc)\n",
        "\n",
        "# Print Model Performance\n",
        "print(\"\\nClassification Report (Random Forest):\\n\", classification_report(y_test, rf_preds))\n",
        "print(\"\\nClassification Report (XGBoost):\\n\", classification_report(y_test, xgb_preds))\n",
        "\n",
        "# Save the trained models\n",
        "import joblib\n",
        "joblib.dump(rf_model, \"random_forest_cognitive_overload.pkl\")\n",
        "joblib.dump(xgb_model, \"xgboost_cognitive_overload.pkl\")\n",
        "\n",
        "print(\"Model training complete. Models saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXuuGIvtZqDX",
        "outputId": "2ad1c2ed-a76b-47ab-fc52-33ca2c8df196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.7843791722296395\n",
            "Random Forest Accuracy: 0.920894526034713\n",
            "XGBoost Accuracy: 0.9479305740987984\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94      2125\n",
            "           1       0.88      0.84      0.86       871\n",
            "\n",
            "    accuracy                           0.92      2996\n",
            "   macro avg       0.91      0.90      0.90      2996\n",
            "weighted avg       0.92      0.92      0.92      2996\n",
            "\n",
            "\n",
            "Classification Report (XGBoost):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      2125\n",
            "           1       0.92      0.90      0.91       871\n",
            "\n",
            "    accuracy                           0.95      2996\n",
            "   macro avg       0.94      0.93      0.94      2996\n",
            "weighted avg       0.95      0.95      0.95      2996\n",
            "\n",
            "Model training complete. Models saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model for Social Engagement Prediction<br>\n",
        "We'll use: <br>✅ Logistic Regression as a baseline model.<br>\n",
        "✅ Random Forest Classifier for better accuracy.<br>\n",
        "✅ XGBoost Classifier for optimized performance.<br>"
      ],
      "metadata": {
        "id": "H7ClQaatagfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset with engineered features\n",
        "df = pd.read_csv(\"engineered_wellbeing_data.csv\")\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['SOCIAL_ACTIVITY_SCORE', 'WORK_PRODUCTIVITY_SCORE', 'SELF_CARE_SCORE', 'STRESS_IMPACT']\n",
        "X = df[features]\n",
        "y = df['SOCIAL_ENGAGEMENT_NEEDS']  # Target variable (1: Needs Engagement, 0: Well Engaged)\n",
        "\n",
        "# Split the data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression Model (Baseline)\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train, y_train)\n",
        "log_preds = log_model.predict(X_test)\n",
        "log_acc = accuracy_score(y_test, log_preds)\n",
        "print(\"Logistic Regression Accuracy:\", log_acc)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, rf_preds)\n",
        "print(\"Random Forest Accuracy:\", rf_acc)\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "print(\"XGBoost Accuracy:\", xgb_acc)\n",
        "\n",
        "# Print Model Performance\n",
        "print(\"\\nClassification Report (Random Forest):\\n\", classification_report(y_test, rf_preds))\n",
        "print(\"\\nClassification Report (XGBoost):\\n\", classification_report(y_test, xgb_preds))\n",
        "\n",
        "# Save the trained models\n",
        "import joblib\n",
        "joblib.dump(rf_model, \"random_forest_social_engagement.pkl\")\n",
        "joblib.dump(xgb_model, \"xgboost_social_engagement.pkl\")\n",
        "\n",
        "print(\"Model training complete. Models saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ad51NeLZsbd",
        "outputId": "ed7e7844-3a84-4f98-911f-6f4a990ab74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.784712950600801\n",
            "Random Forest Accuracy: 0.9472630173564753\n",
            "XGBoost Accuracy: 0.9355807743658211\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95      1692\n",
            "           1       0.94      0.94      0.94      1304\n",
            "\n",
            "    accuracy                           0.95      2996\n",
            "   macro avg       0.95      0.95      0.95      2996\n",
            "weighted avg       0.95      0.95      0.95      2996\n",
            "\n",
            "\n",
            "Classification Report (XGBoost):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      1692\n",
            "           1       0.93      0.93      0.93      1304\n",
            "\n",
            "    accuracy                           0.94      2996\n",
            "   macro avg       0.93      0.93      0.93      2996\n",
            "weighted avg       0.94      0.94      0.94      2996\n",
            "\n",
            "Model training complete. Models saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model for Work-Life Balance Adjustment<br>\n",
        "We'll use: <br>✅ Logistic Regression as a baseline model.<br>\n",
        "✅ Random Forest Classifier for better accuracy.<br>\n",
        "✅ XGBoost Classifier for optimized performance.<br>"
      ],
      "metadata": {
        "id": "6_Ujsduganyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset with engineered features\n",
        "df = pd.read_csv(\"engineered_wellbeing_data.csv\")\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['SOCIAL_ACTIVITY_SCORE', 'WORK_PRODUCTIVITY_SCORE', 'SELF_CARE_SCORE', 'STRESS_IMPACT']\n",
        "X = df[features]\n",
        "y = df['WORK_LIFE_BALANCE_ADJUST']  # Target variable (1: Needs Adjustment, 0: Balanced)\n",
        "\n",
        "# Split the data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression Model (Baseline)\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train, y_train)\n",
        "log_preds = log_model.predict(X_test)\n",
        "log_acc = accuracy_score(y_test, log_preds)\n",
        "print(\"Logistic Regression Accuracy:\", log_acc)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, rf_preds)\n",
        "print(\"Random Forest Accuracy:\", rf_acc)\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "print(\"XGBoost Accuracy:\", xgb_acc)\n",
        "\n",
        "# Print Model Performance\n",
        "print(\"\\nClassification Report (Random Forest):\\n\", classification_report(y_test, rf_preds))\n",
        "print(\"\\nClassification Report (XGBoost):\\n\", classification_report(y_test, xgb_preds))\n",
        "\n",
        "# Save the trained models\n",
        "import joblib\n",
        "joblib.dump(rf_model, \"random_forest_work_life_balance.pkl\")\n",
        "joblib.dump(xgb_model, \"xgboost_work_life_balance.pkl\")\n",
        "\n",
        "print(\"Model training complete. Models saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyZKKlK3Z5f3",
        "outputId": "145cce96-d652-4eb2-dd85-57c0efec4007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8624833110814419\n",
            "Random Forest Accuracy: 0.8648197596795728\n",
            "XGBoost Accuracy: 0.8621495327102804\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87      1501\n",
            "           1       0.87      0.86      0.86      1495\n",
            "\n",
            "    accuracy                           0.86      2996\n",
            "   macro avg       0.86      0.86      0.86      2996\n",
            "weighted avg       0.86      0.86      0.86      2996\n",
            "\n",
            "\n",
            "Classification Report (XGBoost):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86      1501\n",
            "           1       0.87      0.85      0.86      1495\n",
            "\n",
            "    accuracy                           0.86      2996\n",
            "   macro avg       0.86      0.86      0.86      2996\n",
            "weighted avg       0.86      0.86      0.86      2996\n",
            "\n",
            "Model training complete. Models saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained models\n",
        "rf_cognitive_model = joblib.load(\"random_forest_cognitive_overload.pkl\")  # Cognitive Overload\n",
        "rf_social_model = joblib.load(\"random_forest_social_engagement.pkl\")  # Social Engagement Needs\n",
        "rf_balance_model = joblib.load(\"random_forest_work_life_balance.pkl\")  # Work-Life Balance\n",
        "\n",
        "# Load the StandardScaler used during training\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "\n",
        "# Function to take user input\n",
        "def get_user_input():\n",
        "    print(\"\\nEnter your responses to the following questions:\")\n",
        "\n",
        "    # Taking user input for each feature\n",
        "    social_activity = float(input(\"Social Activity Score (e.g., 0-10, based on places visited & social engagement): \"))\n",
        "    work_productivity = float(input(\"Work Productivity Score (e.g., 0-10, based on achievements & task completion): \"))\n",
        "    self_care = float(input(\"Self-Care Score (e.g., 0-10, based on sleep, meditation, & hobbies): \"))\n",
        "    stress_impact = float(input(\"Stress Impact Score (e.g., 0-10, considering daily stress & shouting levels): \"))\n",
        "\n",
        "    return np.array([social_activity, work_productivity, self_care, stress_impact]).reshape(1, -1)\n",
        "\n",
        "# Get user input\n",
        "user_features = get_user_input()\n",
        "\n",
        "# Make predictions\n",
        "cognitive_overload_prediction = rf_cognitive_model.predict(user_features)[0]\n",
        "social_engagement_prediction = rf_social_model.predict(user_features)[0]\n",
        "work_life_balance_prediction = rf_balance_model.predict(user_features)[0]\n",
        "\n",
        "# Output results\n",
        "print(\"\\n📌 **Predictions Based on Your Input:**\")\n",
        "print(\"✅ **Cognitive Overload Prediction:**\", \"YES, you are overloaded 😟\" if cognitive_overload_prediction == 1 else \"NO, you are not overloaded 😊\")\n",
        "print(\"✅ **Social Engagement Needs:**\", \"YES, you need more social engagement 🤝\" if social_engagement_prediction == 1 else \"NO, you are socially engaged 🎉\")\n",
        "print(\"✅ **Work-Life Balance Adjustment:**\", \"YES, you need to adjust your work-life balance ⚖️\" if work_life_balance_prediction == 1 else \"NO, your work-life balance is good! 💼✨\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "288lHpP3ldHS",
        "outputId": "89963a14-d259-459f-8f4e-3c13a24cbe01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your responses to the following questions:\n",
            "Social Activity Score (e.g., 0-10, based on places visited & social engagement): 5\n",
            "Work Productivity Score (e.g., 0-10, based on achievements & task completion): 5\n",
            "Self-Care Score (e.g., 0-10, based on sleep, meditation, & hobbies): 5\n",
            "Stress Impact Score (e.g., 0-10, considering daily stress & shouting levels): 5\n",
            "\n",
            "📌 **Predictions Based on Your Input:**\n",
            "✅ **Cognitive Overload Prediction:** YES, you are overloaded 😟\n",
            "✅ **Social Engagement Needs:** NO, you are socially engaged 🎉\n",
            "✅ **Work-Life Balance Adjustment:** NO, your work-life balance is good! 💼✨\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Predictive Scheduling with LSTM<br>\n",
        "Now that we have models to predict cognitive overload, social engagement needs, and work-life balance adjustments, the next step is to build an LSTM (Long Short-Term Memory) model for dynamic scheduling.\n",
        "\n",
        "This model will:<br> ✅ Analyze user routines over time to suggest the best times for work, socializing, and self-care.<Br>\n",
        "✅ Predict productivity patterns based on past behavior.<br>\n",
        "✅ Provide personalized schedule recommendations to optimize daily activities."
      ],
      "metadata": {
        "id": "Xye2cIXVa2l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset with engineered features\n",
        "df = pd.read_csv(\"engineered_wellbeing_data.csv\")\n",
        "\n",
        "# Define features and target variable for scheduling optimization\n",
        "features = ['SOCIAL_ACTIVITY_SCORE', 'WORK_PRODUCTIVITY_SCORE', 'SELF_CARE_SCORE', 'STRESS_IMPACT']\n",
        "target = 'WORK_LIFE_BALANCE_SCORE'  # Predicting the optimal work-life balance score\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df[features])\n",
        "y = df[target].values.reshape(-1, 1)  # Convert target into a numpy array\n",
        "\n",
        "# Reshape input for LSTM (samples, time steps, features)\n",
        "X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build LSTM model for scheduling optimization\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output layer predicting work-life balance score\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"LSTM Model - Mean Absolute Error: {mae}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"lstm_scheduling_model.h5\")\n",
        "\n",
        "print(\"LSTM scheduling model training complete. Model saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtWqHUwYaAUR",
        "outputId": "61b34ba9-6b7a-4b4b-ccb8-bf40e13331f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.3837 - mae: 0.4717 - val_loss: 0.1687 - val_mae: 0.3278\n",
            "Epoch 2/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.1913 - mae: 0.3519 - val_loss: 0.1738 - val_mae: 0.3349\n",
            "Epoch 3/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1850 - mae: 0.3470 - val_loss: 0.1688 - val_mae: 0.3263\n",
            "Epoch 4/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1857 - mae: 0.3462 - val_loss: 0.1733 - val_mae: 0.3340\n",
            "Epoch 5/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1840 - mae: 0.3460 - val_loss: 0.1674 - val_mae: 0.3266\n",
            "Epoch 6/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.1857 - mae: 0.3465 - val_loss: 0.1686 - val_mae: 0.3287\n",
            "Epoch 7/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.1871 - mae: 0.3471 - val_loss: 0.1676 - val_mae: 0.3276\n",
            "Epoch 8/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1837 - mae: 0.3437 - val_loss: 0.1706 - val_mae: 0.3311\n",
            "Epoch 9/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1859 - mae: 0.3472 - val_loss: 0.1687 - val_mae: 0.3279\n",
            "Epoch 10/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.1852 - mae: 0.3485 - val_loss: 0.1691 - val_mae: 0.3268\n",
            "Epoch 11/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1841 - mae: 0.3443 - val_loss: 0.1671 - val_mae: 0.3267\n",
            "Epoch 12/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1826 - mae: 0.3431 - val_loss: 0.1674 - val_mae: 0.3278\n",
            "Epoch 13/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.1836 - mae: 0.3454 - val_loss: 0.1694 - val_mae: 0.3293\n",
            "Epoch 14/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.1819 - mae: 0.3430 - val_loss: 0.1688 - val_mae: 0.3283\n",
            "Epoch 15/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.1865 - mae: 0.3478 - val_loss: 0.1693 - val_mae: 0.3301\n",
            "Epoch 16/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.1807 - mae: 0.3421 - val_loss: 0.1673 - val_mae: 0.3262\n",
            "Epoch 17/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1806 - mae: 0.3428 - val_loss: 0.1679 - val_mae: 0.3281\n",
            "Epoch 18/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1821 - mae: 0.3431 - val_loss: 0.1715 - val_mae: 0.3286\n",
            "Epoch 19/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1808 - mae: 0.3422 - val_loss: 0.1703 - val_mae: 0.3311\n",
            "Epoch 20/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1822 - mae: 0.3439 - val_loss: 0.1669 - val_mae: 0.3253\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1667 - mae: 0.3238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Model - Mean Absolute Error: 0.32530203461647034\n",
            "LSTM scheduling model training complete. Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictive Scheduling with RNN<br>\n",
        "Now that we've implemented LSTM for scheduling optimization, we will also use RNN (Recurrent Neural Networks) to predict and suggest personalized schedules based on user habits.\n",
        "<Br>\n",
        "This RNN model will:<Br> ✅ Analyze time-series patterns in user routines.<br>\n",
        "✅ Predict productivity levels to optimize task allocation.<br>\n",
        "✅ Suggest scheduling changes dynamically for improved work-life balance."
      ],
      "metadata": {
        "id": "1lu46ri3bBkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset with engineered features\n",
        "df = pd.read_csv(\"engineered_wellbeing_data.csv\")\n",
        "\n",
        "# Define features and target variable for scheduling optimization\n",
        "features = ['SOCIAL_ACTIVITY_SCORE', 'WORK_PRODUCTIVITY_SCORE', 'SELF_CARE_SCORE', 'STRESS_IMPACT']\n",
        "target = 'WORK_LIFE_BALANCE_SCORE'  # Predicting the optimal work-life balance score\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df[features])\n",
        "y = df[target].values.reshape(-1, 1)  # Convert target into a numpy array\n",
        "\n",
        "# Reshape input for RNN (samples, time steps, features)\n",
        "X_rnn = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rnn, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build RNN model for scheduling optimization\n",
        "model_rnn = Sequential([\n",
        "    SimpleRNN(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.3),\n",
        "    SimpleRNN(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output layer predicting work-life balance score\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_rnn.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model_rnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model_rnn.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"RNN Model - Mean Absolute Error: {mae}\")\n",
        "\n",
        "# Save the trained model\n",
        "model_rnn.save(\"rnn_scheduling_model.h5\")\n",
        "\n",
        "print(\"RNN scheduling model training complete. Model saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbKhCZiqbBKy",
        "outputId": "1e45b026-ae40-4238-9375-a0292ea61c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.2644 - mae: 0.4055 - val_loss: 0.1766 - val_mae: 0.3378\n",
            "Epoch 2/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2014 - mae: 0.3612 - val_loss: 0.1729 - val_mae: 0.3340\n",
            "Epoch 3/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1983 - mae: 0.3575 - val_loss: 0.1706 - val_mae: 0.3306\n",
            "Epoch 4/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1965 - mae: 0.3543 - val_loss: 0.1710 - val_mae: 0.3284\n",
            "Epoch 5/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1934 - mae: 0.3530 - val_loss: 0.1691 - val_mae: 0.3283\n",
            "Epoch 6/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1946 - mae: 0.3568 - val_loss: 0.1725 - val_mae: 0.3330\n",
            "Epoch 7/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1925 - mae: 0.3550 - val_loss: 0.1689 - val_mae: 0.3273\n",
            "Epoch 8/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1916 - mae: 0.3536 - val_loss: 0.1745 - val_mae: 0.3317\n",
            "Epoch 9/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1879 - mae: 0.3491 - val_loss: 0.1692 - val_mae: 0.3282\n",
            "Epoch 10/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1898 - mae: 0.3500 - val_loss: 0.1708 - val_mae: 0.3314\n",
            "Epoch 11/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.1909 - mae: 0.3515 - val_loss: 0.1685 - val_mae: 0.3272\n",
            "Epoch 12/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1892 - mae: 0.3500 - val_loss: 0.1736 - val_mae: 0.3338\n",
            "Epoch 13/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1865 - mae: 0.3484 - val_loss: 0.1896 - val_mae: 0.3504\n",
            "Epoch 14/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1869 - mae: 0.3471 - val_loss: 0.1697 - val_mae: 0.3268\n",
            "Epoch 15/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1842 - mae: 0.3445 - val_loss: 0.1697 - val_mae: 0.3270\n",
            "Epoch 16/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1855 - mae: 0.3482 - val_loss: 0.1717 - val_mae: 0.3294\n",
            "Epoch 17/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1856 - mae: 0.3474 - val_loss: 0.1711 - val_mae: 0.3315\n",
            "Epoch 18/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1903 - mae: 0.3523 - val_loss: 0.1697 - val_mae: 0.3268\n",
            "Epoch 19/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1863 - mae: 0.3474 - val_loss: 0.1690 - val_mae: 0.3277\n",
            "Epoch 20/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1883 - mae: 0.3499 - val_loss: 0.1685 - val_mae: 0.3269\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1703 - mae: 0.3262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN Model - Mean Absolute Error: 0.3268507719039917\n",
            "RNN scheduling model training complete. Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# Define custom objects dictionary to include 'mse'\n",
        "custom_objects = {\"mse\": MeanSquaredError()}\n",
        "\n",
        "# Load the trained models with the correct loss function\n",
        "lstm_model = tf.keras.models.load_model(\"lstm_scheduling_model.h5\", custom_objects=custom_objects)\n",
        "rnn_model = tf.keras.models.load_model(\"rnn_scheduling_model.h5\", custom_objects=custom_objects)\n",
        "\n",
        "print(\"✅ Models loaded successfully!\")\n",
        "\n",
        "# Function to take user input\n",
        "def get_user_input():\n",
        "    print(\"\\nEnter your responses to the following questions:\")\n",
        "\n",
        "    social_activity = float(input(\"Social Activity Score (e.g., 0-10, based on places visited & social engagement): \"))\n",
        "    work_productivity = float(input(\"Work Productivity Score (e.g., 0-10, based on achievements & task completion): \"))\n",
        "    self_care = float(input(\"Self-Care Score (e.g., 0-10, based on sleep, meditation, & hobbies): \"))\n",
        "    stress_impact = float(input(\"Stress Impact Score (e.g., 0-10, considering daily stress & shouting levels): \"))\n",
        "\n",
        "    return np.array([social_activity, work_productivity, self_care, stress_impact]).reshape(1, 1, -1)\n",
        "\n",
        "# Get user input\n",
        "user_features = get_user_input()\n",
        "\n",
        "# Predict with both LSTM and RNN models **without scaling**\n",
        "lstm_prediction = lstm_model.predict(user_features)[0][0]\n",
        "rnn_prediction = rnn_model.predict(user_features)[0][0]\n",
        "\n",
        "# Function to generate schedule recommendations based on raw outputs\n",
        "def generate_schedule_recommendation(score):\n",
        "    if score > 8.0:\n",
        "        return \"✅ Your schedule is well-balanced! Maintain current habits. 🏆\"\n",
        "    elif score > 6.0:\n",
        "        return \"🔹 You're productive but need better work-life balance. Try adding more personal time.\"\n",
        "    elif score > 4.0:\n",
        "        return \"🛑 Reduce workload in the morning. Schedule rest breaks in the afternoon.\"\n",
        "    elif score > 2.0:\n",
        "        return \"⚠️ Your work schedule is too packed! Reduce meetings and take downtime.\"\n",
        "    else:\n",
        "        return \"❌ You're overworking! Prioritize self-care and social time.\"\n",
        "\n",
        "# Get recommendations\n",
        "lstm_recommendation = generate_schedule_recommendation(lstm_prediction)\n",
        "rnn_recommendation = generate_schedule_recommendation(rnn_prediction)\n",
        "\n",
        "# Output results\n",
        "print(\"\\n📌 **Predictions Based on Your Input:**\")\n",
        "print(f\"🧠 **LSTM Scheduling Suggestion:** {lstm_recommendation}\")\n",
        "print(f\"📊 **RNN Scheduling Suggestion:** {rnn_recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxUte6M5n5Dp",
        "outputId": "56591165-9a98-414c-c708-c2638b780f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Models loaded successfully!\n",
            "\n",
            "Enter your responses to the following questions:\n",
            "Social Activity Score (e.g., 0-10, based on places visited & social engagement): 8\n",
            "Work Productivity Score (e.g., 0-10, based on achievements & task completion): 7\n",
            "Self-Care Score (e.g., 0-10, based on sleep, meditation, & hobbies): 6\n",
            "Stress Impact Score (e.g., 0-10, considering daily stress & shouting levels): 4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
            "\n",
            "📌 **Predictions Based on Your Input:**\n",
            "🧠 **LSTM Scheduling Suggestion:** 🛑 Reduce workload in the morning. Schedule rest breaks in the afternoon.\n",
            "📊 **RNN Scheduling Suggestion:** ⚠️ Your work schedule is too packed! Reduce meetings and take downtime.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement Learning for Time Optimization<br>\n",
        "Now that we've implemented LSTM and RNN for predictive scheduling, we will use Reinforcement Learning (RL) to dynamically optimize time management based on real-time user behavior.\n",
        "\n",
        "This RL model will:<br> ✅ Prioritize tasks dynamically, rewarding timely completion and penalizing missed activities.<br>\n",
        "✅ Optimize scheduling to improve productivity, social engagement, and self-care balance.<br>\n",
        "✅ Adapt to user behavior over time, ensuring evolving preferences are considered."
      ],
      "metadata": {
        "id": "CFmdOfRQbSp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "# Load the dataset with engineered features\n",
        "df = pd.read_csv(\"engineered_wellbeing_data.csv\")\n",
        "\n",
        "# Define states: User's current work-life balance, social engagement, and stress impact\n",
        "states = df[['WORK_LIFE_BALANCE_SCORE', 'SOCIAL_ACTIVITY_SCORE', 'STRESS_IMPACT']].values\n",
        "\n",
        "# Define actions: Task Rescheduling Options (Delay, Prioritize, Maintain)\n",
        "actions = ['Postpone Task', 'Prioritize Task', 'Maintain Schedule']\n",
        "\n",
        "# Define the Q-table for Q-learning\n",
        "q_table = np.zeros((len(states), len(actions)))\n",
        "\n",
        "# Optimized Hyperparameters\n",
        "learning_rate = 0.3  # Increase learning speed\n",
        "discount_factor = 0.95  # Reward future actions more\n",
        "exploration_rate = 1.0\n",
        "exploration_decay = 0.99  # Faster decay\n",
        "min_exploration_rate = 0.05  # Avoid getting stuck in bad policies\n",
        "episodes = 500  # **Reduced from 5000 to 1000 for faster execution**\n",
        "\n",
        "# Optimized Q-Learning Algorithm\n",
        "for episode in range(episodes):\n",
        "    state_index = random.randint(0, len(states) - 1)  # Start from a random state\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Vectorized Exploration vs Exploitation\n",
        "        action_index = (\n",
        "            random.randint(0, len(actions) - 1) if random.uniform(0, 1) < exploration_rate\n",
        "            else np.argmax(q_table[state_index])\n",
        "        )\n",
        "\n",
        "        # Faster Reward Calculation\n",
        "        reward = (\n",
        "            -1 if actions[action_index] == 'Postpone Task' and states[state_index][1] > 50 else\n",
        "            1 if actions[action_index] == 'Prioritize Task' and states[state_index][2] < 30 else\n",
        "            0.5\n",
        "        )\n",
        "\n",
        "        # Move to next state (More random for faster learning)\n",
        "        next_state_index = random.randint(0, len(states) - 1)\n",
        "\n",
        "        # Vectorized Q-value Update\n",
        "        q_table[state_index, action_index] = (\n",
        "            (1 - learning_rate) * q_table[state_index, action_index]\n",
        "            + learning_rate * (reward + discount_factor * np.max(q_table[next_state_index]))\n",
        "        )\n",
        "\n",
        "        state_index = next_state_index  # Update state\n",
        "\n",
        "        # Stop early for efficiency\n",
        "        if episode > episodes - 100:\n",
        "            done = True\n",
        "\n",
        "    # Faster exploration decay\n",
        "    exploration_rate = max(min_exploration_rate, exploration_rate * exploration_decay)\n",
        "\n",
        "# Save the trained Q-table\n",
        "joblib.dump(q_table, \"q_learning_time_optimization.pkl\")\n",
        "\n",
        "print(\"🚀 Optimized Q-learning model training complete in ~30 minutes. Model saved successfully.\")\n"
      ],
      "metadata": {
        "id": "_dgfK33gbBNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}